<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jupyternotebook on oneAPI Community Page</title>
    <link>http://oneapi-community.github.io/tags/jupyternotebook/</link>
    <description>Recent content in Jupyternotebook on oneAPI Community Page</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Jun 2024 15:25:44 -0700</lastBuildDate>
    <atom:link href="http://oneapi-community.github.io/tags/jupyternotebook/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Insurance Fraud Detection OneAPI</title>
      <link>http://oneapi-community.github.io/projects/insurance-fraud-detection-oneapi/</link>
      <pubDate>Sun, 23 Jun 2024 15:25:44 -0700</pubDate>
      <guid>http://oneapi-community.github.io/projects/insurance-fraud-detection-oneapi/</guid>
      <description>&lt;p&gt;Insurance Fraud Detection Classififcation ML model using OneAPI (Decision Tree)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Intel oneAPI Speech Emotion Recognition</title>
      <link>http://oneapi-community.github.io/projects/intel-oneapi-speech-emotion-recognition/</link>
      <pubDate>Sun, 23 Jun 2024 15:17:39 -0700</pubDate>
      <guid>http://oneapi-community.github.io/projects/intel-oneapi-speech-emotion-recognition/</guid>
      <description>&lt;p&gt;Human-Computer interactions are make it mandatory to get accuracy communications, like both human. If computer identify means we will get clever interaction We might be on the verge of too many screens. It seems like everyday, new versions of common objects are “re-invented” with built-in Wi-Fi and bright touchscreens. A promising antidote to our screen addiction are voice interfaces.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Online Speech Therapist</title>
      <link>http://oneapi-community.github.io/projects/online-speech-therapist/</link>
      <pubDate>Fri, 29 Mar 2024 12:34:35 -0700</pubDate>
      <guid>http://oneapi-community.github.io/projects/online-speech-therapist/</guid>
      <description>&lt;p&gt;Welcome to our platform! Here, we integrate cutting-edge machine learning technology from Hugging Face to assist with speech therapy. Our tools are tailored for doctors, parents, and administrators, making speech assessment and treatment more accessible and efficient. With intuitive features, we simplify addressing speech challenges, ultimately enhancing communication skills. advanced technology to revolutionize speech therapy and improve outcomes for all involved.&#xA;Innovating Speech Therapy: Introducing Groundbreaking Tools for Assessment and Treatment, Intel® oneAPI is used to optimize the models to provide accurate and efficient prediction&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sign Langauge Translator oneAPI</title>
      <link>http://oneapi-community.github.io/projects/sign-langauge-translator-oneapi/</link>
      <pubDate>Fri, 29 Mar 2024 12:24:40 -0700</pubDate>
      <guid>http://oneapi-community.github.io/projects/sign-langauge-translator-oneapi/</guid>
      <description>&lt;p&gt;We will develop a Sign Gesture Language Translator using MediaPipe and the Intel OneAPI Platform. The translator will be able to recognize sign gestures captured from a video stream and convert them into corresponding text or spoken language.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Oneapi Dct</title>
      <link>http://oneapi-community.github.io/projects/oneapi-dct/</link>
      <pubDate>Tue, 31 Oct 2023 12:41:44 -0700</pubDate>
      <guid>http://oneapi-community.github.io/projects/oneapi-dct/</guid>
      <description>&lt;p&gt;Use OneAPI to implement the DCT algorithm. Reference from Intel OneAPI Github.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
